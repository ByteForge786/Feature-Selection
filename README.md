# Feature-Selection

Feature selection is the ML process of finding the subset of features that are most relevant for a better predictive model.

When presented data with very high dimensionality(large no. of features), models usually choke because

1) Less training time.

2) Risk of overfitting.

Feature selection methods can help identify as well as remove redundant and irrelevant attributes from data that do not contribute to the predictive power of the model.

The objective of feature selection is three-fold:

1) Improving the prediction performance of the predictors.

2) Providing faster and more cost-effective predictors.

3) Providing a better understanding of the underlying process that generated the data.

WHY WE NEED IT?
 
All the features in a dataset might not be useful. In a dataset, some features may contribute no information at all, while some features  may contribute similar information as the other features.
So selecting the important features is more important than having a high no. of features and that's what feature selection methods help us do.

This project will take you on an adventure of Feature Selection Methods and how to apply it.
